{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd133ab0",
   "metadata": {},
   "source": [
    "# Notebook: Set Up Local-LLM for BERT Training and Inference\n",
    "\n",
    "### Objective:\n",
    "\n",
    "1. Locate the following files downloaded from Google Research's GitHub Repository:\n",
    "    - A foloder containing three BERT TensorFlow checkpoint files (e.g., `bert_model.ckpt.data-00000-of-00001`, `bert_model.ckpt.index`, `bert_model.ckpt.meta`).\n",
    "    - Metadata about model architecture (e.g., `bert_config.json`).\n",
    "    - A .txt file containing a BERT vocabularly (e.g., `vocab.txt`).\n",
    "2. Convert TensorFlow checkpoints into format for PyTorch.\n",
    "3. Store a .bin file which contains the BERT model parameters in PyTorch compatable format (e.g., `pytorch_model.bin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a9d6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'setup_bert_base' from 'local_llm.convert' (C:\\Users\\Cameron.Webster\\Python\\local-llm\\src\\local_llm\\convert.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlocal_llm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlllm\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Python\\local-llm\\src\\local_llm\\__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# local_llm/__init__.py\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_tf_bert_to_torch, interactive_setup_bert_base, setup_bert_base\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertConfig, BertModel, masked_mean_pool\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbert_wordpiece\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     load_vocab,\n\u001b[32m      8\u001b[39m     BasicTokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     SPECIAL_TOKENS,\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'setup_bert_base' from 'local_llm.convert' (C:\\Users\\Cameron.Webster\\Python\\local-llm\\src\\local_llm\\convert.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import local_llm as lllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fd101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] Using TF checkpoint prefix: C:\\Users\\Cameron.Webster\\Python\\local-llm\\assets\\uncased_L-12_H-768_A-12\\bert_model.ckpt\n",
      "[convert] Loaded tensors: 199 | Skipped: 7\n",
      "[convert] Wrote: C:\\Users\\Cameron.Webster\\Python\\local-llm\\assets\\bert-base-local\\pytorch_model.bin\n",
      "[setup] Copied config → C:\\Users\\Cameron.Webster\\Python\\local-llm\\assets\\bert-base-local\\config.json\n",
      "[setup] Copied vocab → C:\\Users\\Cameron.Webster\\Python\\local-llm\\assets\\bert-base-local\\vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# OPTION 1 SETUP\n",
    "assets_dir = lllm.setup_bert(\n",
    "    checkpoints=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12\",\n",
    "    vocab=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12/vocab.txt\",\n",
    "    config=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/uncased_L-12_H-768_A-12/bert_config.json\",\n",
    "    # optional; by default this would become ..\\assets\\bert-base-local\n",
    "    output_dir=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Now assets_dir should contain:\n",
    "#   pytorch_model.bin\n",
    "#   config.json\n",
    "#   vocab.txt\n",
    "\n",
    "\n",
    "# # OPTION 2 SETUP\n",
    "# assets_dir = lllm.setup_bert(\n",
    "#     model_params=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/pytorch_model.bin\",\n",
    "#     vocab=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/vocab.txt\",\n",
    "#     config=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-base-local/config.json\",\n",
    "#     # output_dir optional; if omitted, uses the folder containing model_params\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97567876",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_dir = lllm.setup_bert(\n",
    "    checkpoints=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/wwm_uncased_L-24_H-1024_A-16\",\n",
    "    vocab=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/wwm_uncased_L-24_H-1024_A-16/vocab.txt\",\n",
    "    config=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/wwm_uncased_L-24_H-1024_A-16/bert_config.json\",\n",
    "    # optional; by default this would become ..\\assets\\bert-base-local\n",
    "    output_dir=r\"C:/Users/Cameron.Webster/Python/local-llm/assets/bert-large-local\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e88660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_internet_requests(url=\"http://www.google.com\", timeout=5):\n",
    "    try:\n",
    "        requests.get(url, timeout=timeout)\n",
    "        return True\n",
    "    except (requests.ConnectionError, requests.Timeout):\n",
    "        return False\n",
    "\n",
    "if check_internet_requests():\n",
    "    print(\"Internet connection available using requests.\")\n",
    "else:\n",
    "    print(\"No internet connection using requests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
